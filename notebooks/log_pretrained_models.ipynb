{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74e5dbd2",
   "metadata": {},
   "source": [
    "# Exemple MLflow : Suivi de deux runs d'entra√Ænement de mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18f19137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"hostephane/ML\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"hostephane/ML\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository hostephane/ML initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository hostephane/ML initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "Device set to use cpu\n",
      "C:\\Users\\steph\\AppData\\Local\\Temp\\ipykernel_29184\\3408250951.py:19: FutureWarning: The 'transformers' MLflow Models integration is known to be compatible with the following package version ranges: ``4.25.1`` -  ``4.33.1``. MLflow Models integrations with transformers may not succeed when used with package versions outside of this range.\n",
      "  mlflow.transformers.log_model(\n",
      "C:\\Users\\steph\\anaconda3\\Lib\\site-packages\\mlflow\\models\\model.py:579: FutureWarning: The 'transformers' MLflow Models integration is known to be compatible with the following package version ranges: ``4.25.1`` -  ``4.33.1``. MLflow Models integrations with transformers may not succeed when used with package versions outside of this range.\n",
      "  flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\n",
      "C:\\Users\\steph\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:3685: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[60715]]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n",
      "2025/06/27 21:28:13 WARNING mlflow.transformers: Attempted to generate a signature for the saved model or pipeline but encountered an error: module transformers has no attribute ConversationalPipeline\n",
      "2025/06/27 21:28:52 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\steph\\AppData\\Local\\Temp\\tmp17cv209g\\model, flavor: transformers), fall back to return ['transformers==4.53.0', 'torch==2.7.1', 'torchvision==0.22.1']. Set logging level to DEBUG to see the full traceback.\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer, pipeline\n",
    "import mlflow\n",
    "import mlflow.transformers\n",
    "import dagshub\n",
    "\n",
    "# üîß DagsHub init\n",
    "dagshub.init(repo_owner='hostephane', repo_name='ML', mlflow=True)\n",
    "mlflow.set_experiment(\"manga_ocr_translation\")\n",
    "\n",
    "# üì¶ Load model/tokenizer\n",
    "tokenizer = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-ja-en\")\n",
    "model = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-ja-en\")\n",
    "\n",
    "# üß™ Build pipeline (important pour que mlflow comprenne que c‚Äôest une t√¢che de traduction)\n",
    "translation_pipeline = pipeline(\"translation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# üöÄ Log via MLflow\n",
    "with mlflow.start_run(run_name=\"marian_pipeline_run\"):\n",
    "    mlflow.transformers.log_model(\n",
    "        transformers_model=translation_pipeline,\n",
    "        artifact_path=\"translation_pipeline\",\n",
    "        input_example=\"„Åì„Çì„Å´„Å°„ÅØ\",\n",
    "    )\n",
    "    mlflow.log_param(\"model_name\", \"Helsinki-NLP/opus-mt-ja-en\")\n",
    "    mlflow.log_param(\"task\", \"translation_ja_to_en\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ccd24ae-108d-4cb8-85e3-c990285c4844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"hostephane/ML\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"hostephane/ML\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository hostephane/ML initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository hostephane/ML initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import dagshub\n",
    "import easyocr\n",
    "import os\n",
    "\n",
    "# Init MLflow avec DagsHub\n",
    "dagshub.init(repo_owner=\"hostephane\", repo_name=\"ML\", mlflow=True)\n",
    "\n",
    "# Cr√©er le lecteur\n",
    "reader = easyocr.Reader(['ja', 'en'])\n",
    "\n",
    "# Dossier o√π sauvegarder le mod√®le (par exemple juste les fichiers internes d'easyocr)\n",
    "model_path = \"easyocr_reader\"\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "# Juste pour illustrer : on sauvegarde un fichier de description du mod√®le\n",
    "with open(os.path.join(model_path, \"info.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"EasyOCR Reader with languages: ['ja', 'en']\")\n",
    "\n",
    "# MLflow run\n",
    "with mlflow.start_run(run_name=\"easyocr_reader\"):\n",
    "    mlflow.log_param(\"type\", \"easyocr\")\n",
    "    mlflow.log_param(\"languages\", \"ja, en\")\n",
    "    mlflow.log_artifacts(model_path, artifact_path=\"easyocr_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b2ba97-1df0-4096-a5d8-a4e4b55666e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
